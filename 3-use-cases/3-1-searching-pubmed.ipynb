{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3.1 Searching PubMed\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/hscells/apis-for-evidence-identification/blob/main/3-use-cases/3-1-searching-pubmed.ipynb) \n",
    "\n",
    "In this notebook, we will show how to use the PubMed API to validate a search query against a set of seed studies. We will then use a large language model to generate a search query for a systematic review and validate it against the same set of seed studies.\n",
    "\n",
    "The first cell below sets up the environment and installs the required packages."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a5771861e18cc83"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade pip -q\n",
    "!pip install --upgrade requests pandas huggingface transformers torch -q\n",
    "import requests\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import transformers.utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T11:18:50.697873Z",
     "start_time": "2024-04-12T11:18:47.927432Z"
    }
   },
   "id": "600481f4ff1baa6c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validating a Search Query\n",
    "\n",
    "We can use the PubMed API to find if our search string is retrieving the seed studies we have while maintaining an acceptable level to total studies to screen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c724c4c90f5b49e"
  },
  {
   "cell_type": "code",
   "source": [
    "search_string = \"\"\"\n",
    "(\"Acne Vulgaris\"[Mesh] OR Acne[tiab] OR Blackheads[tiab] OR Whiteheads[tiab] OR Pimples[tiab]) AND (\"Phototherapy\"[Mesh] OR \"Blue light\"[tiab] OR Phototherapy[tiab] OR Phototherapies[tiab] OR \"Photoradiation therapy\"[tiab] OR \"Photoradiation Therapies\"[tiab] OR \"Light Therapy\"[tiab] OR \"Light Therapies\"[tiab]) AND (Randomized controlled trial[pt] OR controlled clinical trial[pt] OR randomized[tiab] OR randomised[tiab] OR placebo[tiab] OR \"drug therapy\"[sh] OR randomly[tiab] OR trial[tiab] OR groups[tiab]) NOT (Animals[Mesh] not (Animals[Mesh] and Humans[Mesh]))\n",
    "\"\"\"\n",
    "seed_studies = [\"27575854\", \"25594129\", \"20098847\", \"22091799\", \"23278295\", \"24313686\", \"29152718\", \"10809858\",\n",
    "                \"18664153\", \"15379878\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T11:18:53.724495Z",
     "start_time": "2024-04-12T11:18:53.719545Z"
    }
   },
   "id": "e7fcc18e1bdf2a31",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "response = requests.get(  # GET request\n",
    "    url=\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\",  # URL of the API\n",
    "    params={  # Parameters of the request\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": search_string,\n",
    "        \"retmax\": 10_000,  # We can retrieve up to 100,000 studies at a time\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    ").json()  # Parse the response as JSON\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T11:18:55.195399Z",
     "start_time": "2024-04-12T11:18:54.415045Z"
    }
   },
   "id": "22c89879adefd43c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'header': {'type': 'esearch', 'version': '0.3'},\n",
       " 'esearchresult': {'count': '495',\n",
       "  'retmax': '495',\n",
       "  'retstart': '0',\n",
       "  'idlist': ['38464448',\n",
       "   '38316341',\n",
       "   '38297922',\n",
       "   '38243786',\n",
       "   '38070633',\n",
       "   '37984524',\n",
       "   '37951327',\n",
       "   '37943263',\n",
       "   '37931693',\n",
       "   '37881149',\n",
       "   '37843672',\n",
       "   '37805765',\n",
       "   '37643988',\n",
       "   '37634105',\n",
       "   '37592125',\n",
       "   '37558093',\n",
       "   '37446050',\n",
       "   '37328000',\n",
       "   '37097168',\n",
       "   '37095152',\n",
       "   '37073672',\n",
       "   '36946749',\n",
       "   '36842473',\n",
       "   '36740179',\n",
       "   '36704881',\n",
       "   '36676145',\n",
       "   '36587863',\n",
       "   '36564903',\n",
       "   '36505308',\n",
       "   '36384211',\n",
       "   '36381183',\n",
       "   '36208057',\n",
       "   '36199062',\n",
       "   '35951024',\n",
       "   '35917260',\n",
       "   '35829974',\n",
       "   '35792252',\n",
       "   '35791482',\n",
       "   '35789996',\n",
       "   '35763391',\n",
       "   '35760351',\n",
       "   '35500742',\n",
       "   '35490959',\n",
       "   '35309844',\n",
       "   '35286707',\n",
       "   '35176498',\n",
       "   '35132604',\n",
       "   '35044116',\n",
       "   '34981580',\n",
       "   '34929354',\n",
       "   '34919759',\n",
       "   '34840709',\n",
       "   '34799388',\n",
       "   '34797414',\n",
       "   '34752842',\n",
       "   '34696155',\n",
       "   '34674364',\n",
       "   '34613687',\n",
       "   '34600122',\n",
       "   '34582597',\n",
       "   '34536608',\n",
       "   '34500216',\n",
       "   '34409915',\n",
       "   '34407228',\n",
       "   '34368971',\n",
       "   '34363730',\n",
       "   '34333844',\n",
       "   '34287769',\n",
       "   '34273202',\n",
       "   '34260562',\n",
       "   '34157162',\n",
       "   '34138681',\n",
       "   '34082477',\n",
       "   '34076399',\n",
       "   '34042223',\n",
       "   '34041798',\n",
       "   '34015228',\n",
       "   '33992813',\n",
       "   '33938981',\n",
       "   '33860562',\n",
       "   '33730239',\n",
       "   '33725799',\n",
       "   '33588060',\n",
       "   '33538345',\n",
       "   '33516945',\n",
       "   '33471046',\n",
       "   '33453422',\n",
       "   '33443492',\n",
       "   '33398318',\n",
       "   '33326634',\n",
       "   '33300880',\n",
       "   '33226176',\n",
       "   '33166263',\n",
       "   '33157335',\n",
       "   '33084193',\n",
       "   '33083912',\n",
       "   '33073298',\n",
       "   '33070649',\n",
       "   '32800966',\n",
       "   '32737577',\n",
       "   '32728814',\n",
       "   '32623823',\n",
       "   '32554971',\n",
       "   '32492862',\n",
       "   '32454087',\n",
       "   '32449013',\n",
       "   '32384205',\n",
       "   '32376429',\n",
       "   '32274805',\n",
       "   '32061843',\n",
       "   '31989479',\n",
       "   '31981369',\n",
       "   '31870898',\n",
       "   '31712293',\n",
       "   '31654468',\n",
       "   '31587493',\n",
       "   '31525842',\n",
       "   '31398812',\n",
       "   '31392587',\n",
       "   '31187937',\n",
       "   '31180258',\n",
       "   '31172821',\n",
       "   '30951626',\n",
       "   '30836211',\n",
       "   '30825010',\n",
       "   '30789515',\n",
       "   '30406341',\n",
       "   '30273795',\n",
       "   '30118905',\n",
       "   '30074109',\n",
       "   '30039861',\n",
       "   '30006754',\n",
       "   '29993146',\n",
       "   '29933082',\n",
       "   '29921404',\n",
       "   '29790262',\n",
       "   '29752702',\n",
       "   '29722425',\n",
       "   '29709603',\n",
       "   '29705755',\n",
       "   '29683289',\n",
       "   '29541753',\n",
       "   '29417078',\n",
       "   '29390528',\n",
       "   '29356026',\n",
       "   '29266290',\n",
       "   '29152718',\n",
       "   '29054795',\n",
       "   '29020479',\n",
       "   '28927457',\n",
       "   '28873106',\n",
       "   '28703382',\n",
       "   '28692353',\n",
       "   '28647616',\n",
       "   '28580338',\n",
       "   '28528603',\n",
       "   '28512669',\n",
       "   '28500784',\n",
       "   '28476075',\n",
       "   '28447362',\n",
       "   '28388236',\n",
       "   '28338214',\n",
       "   '28332311',\n",
       "   '28328287',\n",
       "   '28276005',\n",
       "   '28130791',\n",
       "   '28127660',\n",
       "   '28118375',\n",
       "   '28095552',\n",
       "   '28081648',\n",
       "   '27575854',\n",
       "   '27762647',\n",
       "   '27738837',\n",
       "   '27670126',\n",
       "   '27565032',\n",
       "   '27529709',\n",
       "   '27507028',\n",
       "   '27421917',\n",
       "   '27416315',\n",
       "   '27416314',\n",
       "   '27387253',\n",
       "   '27371428',\n",
       "   '27354885',\n",
       "   '27336945',\n",
       "   '27272080',\n",
       "   '27259313',\n",
       "   '27180785',\n",
       "   '27110894',\n",
       "   '27090488',\n",
       "   '26993345',\n",
       "   '26977496',\n",
       "   '26957383',\n",
       "   '26945321',\n",
       "   '26897386',\n",
       "   '26875889',\n",
       "   '26854014',\n",
       "   '26839152',\n",
       "   '26820256',\n",
       "   '26712714',\n",
       "   '26663215',\n",
       "   '26660491',\n",
       "   '26558274',\n",
       "   '26507926',\n",
       "   '26404243',\n",
       "   '26155326',\n",
       "   '26116283',\n",
       "   '26066895',\n",
       "   '26066894',\n",
       "   '26065545',\n",
       "   '26059819',\n",
       "   '25919144',\n",
       "   '25810322',\n",
       "   '25772520',\n",
       "   '25748556',\n",
       "   '25735439',\n",
       "   '25705949',\n",
       "   '25612117',\n",
       "   '25594129',\n",
       "   '25449153',\n",
       "   '25388823',\n",
       "   '25310750',\n",
       "   '25226792',\n",
       "   '24930587',\n",
       "   '24899367',\n",
       "   '24863570',\n",
       "   '24590242',\n",
       "   '24528912',\n",
       "   '24528911',\n",
       "   '24354616',\n",
       "   '24313686',\n",
       "   '24284115',\n",
       "   '24267397',\n",
       "   '24199715',\n",
       "   '24190453',\n",
       "   '24143960',\n",
       "   '24131072',\n",
       "   '24114421',\n",
       "   '24062872',\n",
       "   '24001378',\n",
       "   '23986167',\n",
       "   '23789838',\n",
       "   '23711766',\n",
       "   '23657872',\n",
       "   '23619435',\n",
       "   '23581798',\n",
       "   '23458393',\n",
       "   '23397274',\n",
       "   '23379344',\n",
       "   '23302041',\n",
       "   '23278295',\n",
       "   '23254733',\n",
       "   '23181556',\n",
       "   '23163336',\n",
       "   '23062156',\n",
       "   '23046014',\n",
       "   '23016531',\n",
       "   '23016530',\n",
       "   '22971307',\n",
       "   '22949035',\n",
       "   '22766970',\n",
       "   '22671310',\n",
       "   '22640000',\n",
       "   '22615511',\n",
       "   '22591502',\n",
       "   '22409714',\n",
       "   '22385206',\n",
       "   '22369722',\n",
       "   '22292760',\n",
       "   '22123417',\n",
       "   '22122923',\n",
       "   '22095179',\n",
       "   '22095176',\n",
       "   '22091799',\n",
       "   '22057503',\n",
       "   '22023784',\n",
       "   '21981360',\n",
       "   '21910712',\n",
       "   '21865812',\n",
       "   '21865806',\n",
       "   '21788837',\n",
       "   '21723142',\n",
       "   '21692772',\n",
       "   '21481063',\n",
       "   '21455548',\n",
       "   '21426868',\n",
       "   '21414073',\n",
       "   '21412803',\n",
       "   '21411414',\n",
       "   '21352326',\n",
       "   '21254857',\n",
       "   '21250791',\n",
       "   '21191297',\n",
       "   '21142739',\n",
       "   '21142737',\n",
       "   '21095503',\n",
       "   '21061756',\n",
       "   '21034706',\n",
       "   '21034705',\n",
       "   '20944910',\n",
       "   '20930696',\n",
       "   '20883294',\n",
       "   '20814788',\n",
       "   '20814646',\n",
       "   '20738323',\n",
       "   '20633797',\n",
       "   '20633796',\n",
       "   '20584250',\n",
       "   '20491770',\n",
       "   '20384757',\n",
       "   '20367670',\n",
       "   '20232583',\n",
       "   '20230991',\n",
       "   '20213916',\n",
       "   '20166163',\n",
       "   '20110060',\n",
       "   '20098847',\n",
       "   '20098846',\n",
       "   '20082947',\n",
       "   '20028443',\n",
       "   '20002654',\n",
       "   '19932449',\n",
       "   '19907402',\n",
       "   '19894368',\n",
       "   '19894365',\n",
       "   '19874358',\n",
       "   '19851060',\n",
       "   '19796088',\n",
       "   '19708873',\n",
       "   '19688149',\n",
       "   '19653060',\n",
       "   '19639620',\n",
       "   '19588644',\n",
       "   '19549185',\n",
       "   '19537381',\n",
       "   '19438689',\n",
       "   '19391056',\n",
       "   '19389105',\n",
       "   '19250299',\n",
       "   '19239470',\n",
       "   '19239465',\n",
       "   '19217691',\n",
       "   '19207432',\n",
       "   '19152520',\n",
       "   '19112800',\n",
       "   '19083578',\n",
       "   '19076205',\n",
       "   '18991153',\n",
       "   '18945319',\n",
       "   '18664153',\n",
       "   '18486025',\n",
       "   '18400022',\n",
       "   '18394082',\n",
       "   '18284396',\n",
       "   '18280335',\n",
       "   '18227953',\n",
       "   '18221341',\n",
       "   '18191717',\n",
       "   '18038501',\n",
       "   '17966178',\n",
       "   '17953640',\n",
       "   '17903156',\n",
       "   '17803597',\n",
       "   '17760592',\n",
       "   '17663928',\n",
       "   '17635510',\n",
       "   '17598868',\n",
       "   '17598035',\n",
       "   '17550443',\n",
       "   '17546432',\n",
       "   '17483769',\n",
       "   '17451577',\n",
       "   '17374063',\n",
       "   '17348993',\n",
       "   '17252567',\n",
       "   '17225060',\n",
       "   '17126748',\n",
       "   '17126741',\n",
       "   '17126740',\n",
       "   '17126739',\n",
       "   '17097395',\n",
       "   '17030282',\n",
       "   '16989191',\n",
       "   '16983674',\n",
       "   '16971316',\n",
       "   '16958807',\n",
       "   '16935788',\n",
       "   '16918560',\n",
       "   '16911289',\n",
       "   '16788934',\n",
       "   '16774110',\n",
       "   '16772153',\n",
       "   '16766484',\n",
       "   '16719870',\n",
       "   '16634903',\n",
       "   '16566733',\n",
       "   '16546587',\n",
       "   '16537211',\n",
       "   '16485882',\n",
       "   '16485872',\n",
       "   '16468292',\n",
       "   '16313244',\n",
       "   '16302560',\n",
       "   '16249142',\n",
       "   '16229725',\n",
       "   '16221049',\n",
       "   '16188181',\n",
       "   '16167427',\n",
       "   '16092799',\n",
       "   '16049896',\n",
       "   '16042935',\n",
       "   '16042934',\n",
       "   '16020203',\n",
       "   '15888131',\n",
       "   '15801258',\n",
       "   '15719833',\n",
       "   '15696987',\n",
       "   '15696715',\n",
       "   '15624737',\n",
       "   '15624736',\n",
       "   '15379878',\n",
       "   '15377348',\n",
       "   '15376545',\n",
       "   '15274696',\n",
       "   '15250771',\n",
       "   '15199033',\n",
       "   '15171775',\n",
       "   '15122361',\n",
       "   '15087589',\n",
       "   '14964759',\n",
       "   '14964758',\n",
       "   '14964757',\n",
       "   '14677157',\n",
       "   '14507231',\n",
       "   '12884461',\n",
       "   '12877231',\n",
       "   '12850803',\n",
       "   '12627995',\n",
       "   '12621801',\n",
       "   '12589953',\n",
       "   '12566803',\n",
       "   '12410680',\n",
       "   '12054327',\n",
       "   '12007011',\n",
       "   '11966684',\n",
       "   '11903225',\n",
       "   '11772241',\n",
       "   '11584773',\n",
       "   '11453825',\n",
       "   '11404627',\n",
       "   '11260017',\n",
       "   '10987863',\n",
       "   '10951234',\n",
       "   '10809858',\n",
       "   '9068732',\n",
       "   '8977669',\n",
       "   '8682969',\n",
       "   '1533716',\n",
       "   '1835402',\n",
       "   '1756019',\n",
       "   '2148629',\n",
       "   '2748434',\n",
       "   '2964889',\n",
       "   '3315625',\n",
       "   '2942854',\n",
       "   '2932455',\n",
       "   '2931338',\n",
       "   '3161169',\n",
       "   '6235684',\n",
       "   '6225067',\n",
       "   '6224672',\n",
       "   '6224708',\n",
       "   '6217805',\n",
       "   '6447320',\n",
       "   '156625',\n",
       "   '150260',\n",
       "   '148005',\n",
       "   '147054',\n",
       "   '82341',\n",
       "   '144541',\n",
       "   '144455',\n",
       "   '138356',\n",
       "   '135977',\n",
       "   '134884',\n",
       "   '128124',\n",
       "   '127434',\n",
       "   '127433',\n",
       "   '4279529',\n",
       "   '4278415',\n",
       "   '4275327',\n",
       "   '4279812',\n",
       "   '4277911',\n",
       "   '4264172',\n",
       "   '4250512',\n",
       "   '4245924',\n",
       "   '4223790'],\n",
       "  'translationset': [{'from': 'Animals[Mesh]', 'to': '\"animals\"[MeSH Terms]'},\n",
       "   {'from': 'Humans[Mesh]', 'to': '\"humans\"[MeSH Terms]'}],\n",
       "  'querytranslation': '((\"Acne Vulgaris\"[MeSH Terms] OR \"Acne\"[Title/Abstract] OR \"Blackheads\"[Title/Abstract] OR \"Whiteheads\"[Title/Abstract] OR \"Pimples\"[Title/Abstract]) AND (\"Phototherapy\"[MeSH Terms] OR \"Blue light\"[Title/Abstract] OR \"Phototherapy\"[Title/Abstract] OR \"Phototherapies\"[Title/Abstract] OR \"Photoradiation therapy\"[Title/Abstract] OR \"Light Therapy\"[Title/Abstract] OR \"Light Therapies\"[Title/Abstract]) AND (\"randomized controlled trial\"[Publication Type] OR \"controlled clinical trial\"[Publication Type] OR \"Randomized\"[Title/Abstract] OR \"randomised\"[Title/Abstract] OR \"placebo\"[Title/Abstract] OR \"drug therapy\"[MeSH Subheading] OR \"randomly\"[Title/Abstract] OR \"trial\"[Title/Abstract] OR \"groups\"[Title/Abstract])) NOT (\"animals\"[MeSH Terms] NOT (\"animals\"[MeSH Terms] AND (\"humans\"[MeSH Terms])))',\n",
       "  'warninglist': {'phrasesignored': ['and'],\n",
       "   'quotedphrasesnotfound': ['\"Photoradiation Therapies\"[tiab]'],\n",
       "   'outputmessages': ['Restrictions achieved. start and count adjusted to 0, 9999']}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:22:17.547752Z",
     "start_time": "2024-04-12T11:22:17.541681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_search(seed_studies, response):\n",
    "    total_studies = int(response[\"esearchresult\"][\"count\"])\n",
    "    retrieved_studies = response[\"esearchresult\"][\"idlist\"]\n",
    "    retrieved_seed_studies = []\n",
    "    for study in seed_studies:\n",
    "        if study in retrieved_studies:\n",
    "            retrieved_seed_studies.append(study)\n",
    "    return total_studies, len(retrieved_seed_studies), retrieved_seed_studies"
   ],
   "id": "4c1501da103e3089",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:24:05.979506Z",
     "start_time": "2024-04-12T11:24:05.975486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retrieved_studies, retrieved_seed_studies, _ = validate_search(seed_studies, response)\n",
    "print(f\"Total studies retrieved: {retrieved_studies}\")\n",
    "print(f\"Retrieved {retrieved_seed_studies} out of {len(seed_studies)} studies.\")"
   ],
   "id": "22d96ebfe2ca03e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total studies retrieved: 495\n",
      "Retrieved 10 out of 10 studies.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:24:08.568886Z",
     "start_time": "2024-04-12T11:24:08.566031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Precision:\", retrieved_seed_studies / retrieved_studies)\n",
    "print(\"Recall:\", retrieved_seed_studies / len(seed_studies))"
   ],
   "id": "4b67f5575dc6a563",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.020202020202020204\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:52:26.953040Z",
     "start_time": "2024-04-12T08:52:26.949631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This cell is required if running on Apple Silicon. It can otherwise be ignored.\n",
    "%env PYTORCH_ENABLE_MPS_FALLBACK=1"
   ],
   "id": "1ca531f1716cabc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating Search Queries with LLMs\n",
    "\n",
    "A [recent paper](https://dl.acm.org/doi/pdf/10.1145/3539618.3591703) used ChatGPT to generate search queries for systematic reviews. Since then, there have been many open-source models that are just as good if not better than ChatGPT. In the next set of cells, we will use one of these models to replicate the results of the paper.\n",
    "\n",
    "In the first cell below, we define a few lines of code that will help us interact with the model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6361c652dab5f876"
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class ChatAssistant:\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda\"\n",
    "        elif transformers.utils.is_torch_mps_available():\n",
    "            device = \"mps\"\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        self.pipe = pipeline(\"text-generation\", model=\"BioMistral/BioMistral-7B-SLERP\", torch_dtype=torch.bfloat16,\n",
    "                             device_map=device)\n",
    "        self.context = []\n",
    "        self.outputs = []\n",
    "\n",
    "    def new_chat(self):\n",
    "        self.context = []\n",
    "        self.outputs = []\n",
    "\n",
    "    def chat(self, message):\n",
    "        prompt = self.pipe.tokenizer.apply_chat_template(self.context + [{\"role\": \"user\", \"content\": message}],\n",
    "                                                         tokenize=False, add_generation_prompt=True)\n",
    "        outputs = self.pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "        self.context.append({\"role\": \"user\", \"content\": message})\n",
    "        self.context.append({\"role\": \"assistant\", \"content\": outputs[0][\"generated_text\"]})\n",
    "        self.outputs.append(outputs[0][\"generated_text\"].split(\"[/INST]\")[-1])\n",
    "        print(self.outputs[-1])\n",
    "\n",
    "\n",
    "assistant = ChatAssistant()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T11:14:57.375867Z",
     "start_time": "2024-04-12T11:14:53.612629Z"
    }
   },
   "id": "ee5487fc50d0d6bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e57e9a4c94442708c263256b48a9e4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 26\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs\u001B[38;5;241m.\u001B[39mappend(outputs[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[/INST]\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     23\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m---> 26\u001B[0m assistant \u001B[38;5;241m=\u001B[39m \u001B[43mChatAssistant\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m, in \u001B[0;36mChatAssistant.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpipe \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext-generation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBioMistral/BioMistral-7B-SLERP\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbfloat16\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/pipelines/__init__.py:905\u001B[0m, in \u001B[0;36mpipeline\u001B[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001B[0m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m framework \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    904\u001B[0m     model_classes \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m: targeted_task[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m: targeted_task[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m]}\n\u001B[0;32m--> 905\u001B[0m     framework, model \u001B[38;5;241m=\u001B[39m \u001B[43minfer_framework_load_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    906\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    907\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_classes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    908\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    909\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframework\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframework\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    910\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    911\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    912\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    913\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    915\u001B[0m model_config \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\n\u001B[1;32m    916\u001B[0m hub_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39m_commit_hash\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/pipelines/base.py:281\u001B[0m, in \u001B[0;36minfer_framework_load_model\u001B[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m     logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    277\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to load the model with Tensorflow.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m     )\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 281\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meval\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    283\u001B[0m         model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:563\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    562\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[0;32m--> 563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    564\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    567\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    569\u001B[0m )\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/modeling_utils.py:3677\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3668\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_orig \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3669\u001B[0m         torch\u001B[38;5;241m.\u001B[39mset_default_dtype(dtype_orig)\n\u001B[1;32m   3670\u001B[0m     (\n\u001B[1;32m   3671\u001B[0m         model,\n\u001B[1;32m   3672\u001B[0m         missing_keys,\n\u001B[1;32m   3673\u001B[0m         unexpected_keys,\n\u001B[1;32m   3674\u001B[0m         mismatched_keys,\n\u001B[1;32m   3675\u001B[0m         offload_index,\n\u001B[1;32m   3676\u001B[0m         error_msgs,\n\u001B[0;32m-> 3677\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_pretrained_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3679\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3680\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloaded_state_dict_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# XXX: rename?\u001B[39;49;00m\n\u001B[1;32m   3681\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresolved_archive_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3682\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3683\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_mismatched_sizes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3684\u001B[0m \u001B[43m        \u001B[49m\u001B[43msharded_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharded_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3685\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_fast_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_fast_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3686\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3687\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3688\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3689\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffload_state_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_state_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3690\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3691\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3692\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3693\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3695\u001B[0m \u001B[38;5;66;03m# make sure token embedding weights are still tied if needed\u001B[39;00m\n\u001B[1;32m   3696\u001B[0m model\u001B[38;5;241m.\u001B[39mtie_weights()\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/modeling_utils.py:4104\u001B[0m, in \u001B[0;36mPreTrainedModel._load_pretrained_model\u001B[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001B[0m\n\u001B[1;32m   4100\u001B[0m                 set_module_tensor_to_device(\n\u001B[1;32m   4101\u001B[0m                     model_to_load, key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;241m*\u001B[39mparam\u001B[38;5;241m.\u001B[39msize(), dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   4102\u001B[0m                 )\n\u001B[1;32m   4103\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4104\u001B[0m         new_error_msgs, offload_index, state_dict_index \u001B[38;5;241m=\u001B[39m \u001B[43m_load_state_dict_into_meta_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4105\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_to_load\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4106\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4107\u001B[0m \u001B[43m            \u001B[49m\u001B[43mloaded_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4108\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstart_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4109\u001B[0m \u001B[43m            \u001B[49m\u001B[43mexpected_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4110\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4111\u001B[0m \u001B[43m            \u001B[49m\u001B[43moffload_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4112\u001B[0m \u001B[43m            \u001B[49m\u001B[43moffload_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffload_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4113\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate_dict_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate_dict_folder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4114\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstate_dict_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstate_dict_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4115\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4116\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhf_quantizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4117\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_safetensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_safetensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4118\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_fp32_modules\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4119\u001B[0m \u001B[43m            \u001B[49m\u001B[43munexpected_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munexpected_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4120\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4121\u001B[0m         error_msgs \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m new_error_msgs\n\u001B[1;32m   4122\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/modeling_utils.py:886\u001B[0m, in \u001B[0;36m_load_state_dict_into_meta_model\u001B[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001B[0m\n\u001B[1;32m    875\u001B[0m     state_dict_index \u001B[38;5;241m=\u001B[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001B[1;32m    876\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m (\n\u001B[1;32m    877\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m is_quantized\n\u001B[1;32m    878\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m hf_quantizer\u001B[38;5;241m.\u001B[39mrequires_parameters_quantization)\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    884\u001B[0m ):\n\u001B[1;32m    885\u001B[0m     \u001B[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001B[39;00m\n\u001B[0;32m--> 886\u001B[0m     \u001B[43mset_module_tensor_to_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_device\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mset_module_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    888\u001B[0m     hf_quantizer\u001B[38;5;241m.\u001B[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/accelerate/utils/modeling.py:399\u001B[0m, in \u001B[0;36mset_module_tensor_to_device\u001B[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001B[0m\n\u001B[1;32m    397\u001B[0m             module\u001B[38;5;241m.\u001B[39m_parameters[tensor_name] \u001B[38;5;241m=\u001B[39m param_cls(new_value, requires_grad\u001B[38;5;241m=\u001B[39mold_value\u001B[38;5;241m.\u001B[39mrequires_grad)\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 399\u001B[0m     new_value \u001B[38;5;241m=\u001B[39m \u001B[43mvalue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    401\u001B[0m     new_value \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(value, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we define some data that we will use inside the prompts to the model.",
   "id": "237bae1b3a0d6723"
  },
  {
   "cell_type": "code",
   "source": [
    "statement = \"Blue-Light Therapy for Acne Vulgaris\"\n",
    "title = \"A randomized controlled study for the treatment of acne vulgaris using high-intensity 414 nm solid state diode arrays.\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T08:53:33.353995Z",
     "start_time": "2024-04-12T08:53:33.344968Z"
    }
   },
   "id": "6282dd04891dfd89",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then, we can start a new chat with the model we created and have it follow a series of instructions to generate a search query.",
   "id": "957521d4c27be0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T09:44:00.058188Z",
     "start_time": "2024-04-12T08:53:34.607558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assistant.new_chat()\n",
    "\n",
    "assistant.chat(\n",
    "    f\"Follow my instructions precisely to develop a highly effective Boolean query for a medical systematic review literature search. Do not explain or elaborate. First, Given the following statement and title from a relevant study, identify 20 terms or phrases that are relevant. The terms you identify will be used to retrieve more relevant studies, so be careful that the terms you choose are not too broad. statement: {statement} title: {title}\")\n",
    "\n",
    "assistant.chat(\n",
    "    \"For each item in the list you created in step 1, classify it into as of three categories: terms relating to health conditions (A), terms relating to a treatment (B), terms relating to types of study design (C). When an item does not fit one of these categories, mark it as (N/A). Do not explain or elaborate.\")\n",
    "\n",
    "assistant.chat(\n",
    "    \"Using the categorised list you created in step 2, use your expert knowledge to create a valid Boolean query that can be submitted to PubMed which groups together items from each category. Also add relevant MeSH terms into the query where necessary. Each main clause of the query must correspond to a PICO element. Do not explain or elaborate.\")"
   ],
   "id": "4f9c6dc8381e6d26",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/Users/harry/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/generation/stopping_criteria.py:149: UserWarning: The operator 'aten::isin.Tensor_Tensor_out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  is_done = torch.isin(input_ids[:, -1], self.eos_token_id.to(input_ids.device))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m assistant\u001B[38;5;241m.\u001B[39mnew_chat()\n\u001B[0;32m----> 3\u001B[0m \u001B[43massistant\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mFollow my instructions precisely to develop a highly effective Boolean query for a medical systematic review literature search. Do not explain or elaborate. First, Given the following statement and title from a relevant study, identify 20 terms or phrases that are relevant. The terms you identify will be used to retrieve more relevant studies, so be careful that the terms you choose are not too broad. statement: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mstatement\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m title: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtitle\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m assistant\u001B[38;5;241m.\u001B[39mchat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor each item in the list you created in step 1, classify it into as of three categories: terms relating to health conditions (A), terms relating to a treatment (B), terms relating to types of study design (C). When an item does not fit one of these categories, mark it as (N/A). Do not explain or elaborate.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m assistant\u001B[38;5;241m.\u001B[39mchat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing the categorised list you created in step 2, create a Boolean query that can be submitted to PubMed which groups together items from each category. Also add relevant MeSH terms into the query where necessary. Each main clause of the query must correspond to a PICO element. The final query must be a valid PubMed query.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[2], line 17\u001B[0m, in \u001B[0;36mChatAssistant.chat\u001B[0;34m(self, message)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchat\u001B[39m(\u001B[38;5;28mself\u001B[39m, message):\n\u001B[1;32m     15\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpipe\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mapply_chat_template(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext \u001B[38;5;241m+\u001B[39m [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: message}], tokenize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     16\u001B[0m                                                 add_generation_prompt\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 17\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.95\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: message})\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massistant\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: outputs[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgenerated_text\u001B[39m\u001B[38;5;124m\"\u001B[39m]})\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:240\u001B[0m, in \u001B[0;36mTextGenerationPipeline.__call__\u001B[0;34m(self, text_inputs, **kwargs)\u001B[0m\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(chats, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtext_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/pipelines/base.py:1220\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1212\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1213\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1214\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         )\n\u001B[1;32m   1218\u001B[0m     )\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/pipelines/base.py:1227\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1225\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1226\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1227\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1228\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1229\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/pipelines/base.py:1126\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m   1124\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m   1125\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1126\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1127\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:327\u001B[0m, in \u001B[0;36mTextGenerationPipeline._forward\u001B[0;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[1;32m    324\u001B[0m         generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin_length\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m prefix_length\n\u001B[1;32m    326\u001B[0m \u001B[38;5;66;03m# BS x SL\u001B[39;00m\n\u001B[0;32m--> 327\u001B[0m generated_sequence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m out_b \u001B[38;5;241m=\u001B[39m generated_sequence\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/generation/utils.py:1618\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1610\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   1611\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1612\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   1613\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   1614\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1615\u001B[0m     )\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;66;03m# 13. run sample\u001B[39;00m\n\u001B[0;32m-> 1618\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1619\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1620\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1621\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_warper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_warper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1622\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1623\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1624\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1625\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_logits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_logits\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1626\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1627\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1628\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1629\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1630\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1632\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mBEAM_SEARCH:\n\u001B[1;32m   1633\u001B[0m     \u001B[38;5;66;03m# 11. prepare beam search scorer\u001B[39;00m\n\u001B[1;32m   1634\u001B[0m     beam_scorer \u001B[38;5;241m=\u001B[39m BeamSearchScorer(\n\u001B[1;32m   1635\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1636\u001B[0m         num_beams\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_beams,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1641\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mmax_length,\n\u001B[1;32m   1642\u001B[0m     )\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/generation/utils.py:2774\u001B[0m, in \u001B[0;36mGenerationMixin._sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2771\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   2773\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 2774\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2775\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2776\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2777\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2778\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2779\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2781\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2782\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:1157\u001B[0m, in \u001B[0;36mMistralForCausalLM.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1154\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m   1156\u001B[0m \u001B[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001B[39;00m\n\u001B[0;32m-> 1157\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1158\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1161\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1164\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1165\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1166\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1167\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1169\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1170\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(hidden_states)\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:1042\u001B[0m, in \u001B[0;36mMistralModel.forward\u001B[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1032\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1033\u001B[0m         decoder_layer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m   1034\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1039\u001B[0m         use_cache,\n\u001B[1;32m   1040\u001B[0m     )\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1042\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1043\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1044\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1045\u001B[0m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1046\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1047\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1048\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1049\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1051\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1053\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:757\u001B[0m, in \u001B[0;36mMistralDecoderLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    754\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_layernorm(hidden_states)\n\u001B[1;32m    756\u001B[0m \u001B[38;5;66;03m# Self Attention\u001B[39;00m\n\u001B[0;32m--> 757\u001B[0m hidden_states, self_attn_weights, present_key_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    758\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    759\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    760\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    761\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    762\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    763\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    764\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    765\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m residual \u001B[38;5;241m+\u001B[39m hidden_states\n\u001B[1;32m    767\u001B[0m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Data/apis-for-evidence-identification/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:688\u001B[0m, in \u001B[0;36mMistralSdpaAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001B[0m\n\u001B[1;32m    685\u001B[0m     key_states \u001B[38;5;241m=\u001B[39m key_states\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[1;32m    686\u001B[0m     value_states \u001B[38;5;241m=\u001B[39m value_states\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m--> 688\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaled_dot_product_attention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    689\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    690\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention_dropout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# The q_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create a causal mask in case q_len == 1.\u001B[39;49;00m\n\u001B[1;32m    695\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mq_len\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    698\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[1;32m    699\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mview(bsz, q_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We should see the generated query above, but we can also extract it from the model directly.",
   "id": "ddae9cd4e251b4bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:17:09.243254Z",
     "start_time": "2024-04-12T11:17:09.197395Z"
    }
   },
   "cell_type": "code",
   "source": "generated_search_string = assistant.outputs[-1]",
   "id": "10fabd6e9ebd3027",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assistant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m generated_search_string \u001B[38;5;241m=\u001B[39m \u001B[43massistant\u001B[49m\u001B[38;5;241m.\u001B[39moutputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'assistant' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can then use the same code we used before for our manually created search string to validate the search query generated by the model. We use the PubMed API to search this time using the generated search string.",
   "id": "814df5f7e3b1ae3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:29:36.608789Z",
     "start_time": "2024-04-12T11:29:36.577578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = requests.get(  # GET request\n",
    "    url=\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\",  # URL of the API\n",
    "    params={  # Parameters of the request\n",
    "        \"db\": \"pubmed\",\n",
    "        \"term\": generated_search_string,\n",
    "        \"retmax\": 10_000,  # We can retrieve up to 100,000 studies at a time\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    ").json()  # Parse the response as JSON\n",
    "\n",
    "generated_retrieved_studies, generated_retrieved_seed_studies, _ = validate_search(seed_studies, response)"
   ],
   "id": "7abff9140e2e7ab8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_search_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(  \u001B[38;5;66;03m# GET request\u001B[39;00m\n\u001B[1;32m      2\u001B[0m     url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\u001B[39m\u001B[38;5;124m\"\u001B[39m,  \u001B[38;5;66;03m# URL of the API\u001B[39;00m\n\u001B[1;32m      3\u001B[0m     params\u001B[38;5;241m=\u001B[39m{  \u001B[38;5;66;03m# Parameters of the request\u001B[39;00m\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdb\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpubmed\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 5\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mterm\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mgenerated_search_string\u001B[49m,\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mretmax\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m10_000\u001B[39m,  \u001B[38;5;66;03m# We can retrieve up to 100,000 studies at a time\u001B[39;00m\n\u001B[1;32m      7\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      8\u001B[0m     }\n\u001B[1;32m      9\u001B[0m )\u001B[38;5;241m.\u001B[39mjson()  \u001B[38;5;66;03m# Parse the response as JSON\u001B[39;00m\n\u001B[1;32m     11\u001B[0m generated_retrieved_studies, generated_retrieved_seed_studies, _ \u001B[38;5;241m=\u001B[39m validate_search(seed_studies, response)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'generated_search_string' is not defined"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:29:37.184560Z",
     "start_time": "2024-04-12T11:29:37.174956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Total studies retrieved: {generated_retrieved_studies}\")\n",
    "print(f\"Retrieved {generated_retrieved_seed_studies} out of {len(seed_studies)} studies.\")"
   ],
   "id": "ef9d76639f90fc97",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_retrieved_studies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal studies retrieved: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mgenerated_retrieved_studies\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrieved \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgenerated_retrieved_seed_studies\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m out of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(seed_studies)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m studies.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'generated_retrieved_studies' is not defined"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T11:29:37.657628Z",
     "start_time": "2024-04-12T11:29:37.644935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Precision:\", generated_retrieved_seed_studies / generated_retrieved_studies)\n",
    "print(\"Recall:\", generated_retrieved_seed_studies / len(seed_studies))"
   ],
   "id": "5bcf76706cbcc4f2",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_retrieved_seed_studies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrecision:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mgenerated_retrieved_seed_studies\u001B[49m \u001B[38;5;241m/\u001B[39m generated_retrieved_studies)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecall:\u001B[39m\u001B[38;5;124m\"\u001B[39m, generated_retrieved_seed_studies \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(seed_studies))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'generated_retrieved_seed_studies' is not defined"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've shown how to automatically validate searches using a set of seed studies using the PubMed API. We then used a local large language model to generate a search query for a systematic review and validated it against the same set of seed studies.\n",
    "\n",
    "---\n",
    "[top](https://github.com/hscells/apis-for-evidence-identification)<br/>\n",
    "[next: Searching ClinicalTrials.gov](https://github.com/hscells/apis-for-evidence-identification/blob/main/3-use-cases/3-2-clinicaltrials-gov.ipynb)<br/>\n",
    "[previous: Using APIs via HTTPie](https://github.com/hscells/apis-for-evidence-identification/blob/main/3-use-cases/3-1-searching-pubmed.ipynb)<br/>"
   ],
   "id": "a0c7bdd651f50bde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
